{"cells":[{"cell_type":"markdown","metadata":{"id":"eXXzvbjT2YT2"},"source":["#  TRAFFIC SIGN DETECTION USING CONVOLUTIONAL NEURAL NETWORK"]},{"cell_type":"markdown","metadata":{"id":"Wv_vYfAY2YT3"},"source":["- Developed a Deep Convolutional Neural Network Model that classifies the images of traffic signs.\n","- Trained the model using the German Traffic Sign Dataset.\n","- Implemented the Convolutional Neural Network Model based on **LeNet Architecture**.\n","- The model will classify the images of traffic signs into 43 different classes.\n","- Classes are as listed below:\n","\n","    - 0 - Speed limit (20km/h)\n","    - 1 - Speed limit (30km/h)\n","    - 2 - Speed limit (50km/h)\n","    - 3 - Speed limit (60km/h)\n","    - 4 - Speed limit (70km/h)\n","    - 5 - Speed limit (80km/h)\n","    - 6 - End of speed limit (80km/h)\n","    - 7 - Speed limit (100km/h)\n","    - 8 - Speed limit (120km/h)\n","    - 9 - No passing\n","    - 10 - No passing for vehicles over 3.5 metric tons\n","    - 11 - Right-of-way at the next intersection\n","    - 12 - Priority road\n","    - 13 - Yield\n","    - 14 - Stop\n","    - 15 - No vehicles\n","    - 16 - Vehicles over 3.5 metric tons prohibited\n","    - 17 - No entry\n","    - 18 - General caution\n","    - 19 - Dangerous curve to the left\n","    - 20 - Dangerous curve to the right\n","    - 21 - Double curve\n","    - 22 - Bumpy road\n","    - 23 - Slippery road\n","    - 24 - Road narrows on the right\n","    - 25 - Road work\n","    - 26 - Traffic signals\n","    - 27 - Pedestrians\n","    - 28 - Children crossing\n","    - 29 - Bicycles crossing\n","    - 30 - Beware of ice/snow\n","    - 31 - Wild animals crossing\n","    - 32 - End of all speed and passing limits\n","    - 33 - Turn right ahead\n","    - 34 - Turn left ahead\n","    - 35 - Ahead only\n","    - 36 - Go straight or right\n","    - 37 - Go straight or left\n","    - 38 - Keep right\n","    - 39 - Keep left\n","    - 40 - Roundabout mandatory\n","    - 41 - End of no passing\n","    - 42 - End of no passing by vehicles over 3.5 metric tons"]},{"cell_type":"markdown","metadata":{"id":"aVFMegZS2YT4"},"source":["# STEP 1: IMPORTING LIBRARIES AND DATASET"]},{"cell_type":"markdown","metadata":{"id":"BFrHp9Vk2YT4"},"source":["# (i) Importing Python Libraries  "]},{"cell_type":"code","execution_count":1,"metadata":{"id":"5fGGvYNM2YT4","executionInfo":{"status":"ok","timestamp":1733191112171,"user_tz":480,"elapsed":9621,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pickle\n","import seaborn as sns\n","import random\n","import csv"]},{"cell_type":"markdown","metadata":{"id":"gB1HJARv2YT5"},"source":["# (ii) Importing Dataset"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"REuArgeM2gen","executionInfo":{"status":"ok","timestamp":1733191189439,"user_tz":480,"elapsed":77270,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}},"outputId":"20300a9c-535d-427a-b98d-d1a06ca83f7e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"i9Mvfw0u2YT5","executionInfo":{"status":"error","timestamp":1733191189796,"user_tz":480,"elapsed":361,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}},"colab":{"base_uri":"https://localhost:8080/","height":201},"outputId":"97e0e9a8-e59f-4857-8252-e340046c766b"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/ColabNotebooks/proj/traffic-signs-data/train.p'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-af3199661f2b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Dataset is mainly divided into three categories -> Training, Validation and Testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/ColabNotebooks/proj/traffic-signs-data/train.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/ColabNotebooks/proj/traffic-signs-data/valid.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ColabNotebooks/proj/traffic-signs-data/train.p'"]}],"source":["#Dataset is mainly divided into three categories -> Training, Validation and Testing set\n","\n","with open(\"/content/drive/MyDrive/ColabNotebooks/proj/traffic-signs-data/train.p\", mode='rb') as training_data:\n","    train = pickle.load(training_data)\n","with open(\"/content/drive/MyDrive/ColabNotebooks/proj/traffic-signs-data/valid.p\", mode='rb') as validation_data:\n","    valid = pickle.load(validation_data)\n","with open(\"/content/drive/MyDrive/ColabNotebooks/proj/traffic-signs-data/test.p\", mode='rb') as testing_data:\n","    test = pickle.load(testing_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"blOEi0hC2YT5","executionInfo":{"status":"aborted","timestamp":1733191189797,"user_tz":480,"elapsed":6,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["# Mapping ClassID to Traffic sign names\n","\n","signs = []\n","with open('/content/drive/MyDrive/ColabNotebooks/proj/signnames.csv', 'r') as csvfile:\n","    signnames = csv.reader(csvfile, delimiter=',')\n","    next(signnames,None)\n","    for row in signnames:\n","        signs.append(row[1])\n","    csvfile.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D3K7iJxr2YT5","executionInfo":{"status":"aborted","timestamp":1733191189797,"user_tz":480,"elapsed":5,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["#Dividing our datasets into features and labels\n","\n","X_train, y_train = train['features'], train['labels']\n","X_validation, y_validation = valid['features'], valid['labels']\n","X_test, y_test = test['features'], test['labels']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TEnmCASt2YT6","executionInfo":{"status":"aborted","timestamp":1733191189797,"user_tz":480,"elapsed":5,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["X_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g30MpNXj2YT6","executionInfo":{"status":"aborted","timestamp":1733191189797,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["y_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kx0UBj7h2YT6","executionInfo":{"status":"aborted","timestamp":1733191189797,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["# Number of training examples\n","n_train = X_train.shape[0]\n","\n","# Number of testing examples\n","n_test = X_test.shape[0]\n","\n","# Number of validation examples.\n","n_validation = X_validation.shape[0]\n","\n","# Shape of a traffic sign image\n","image_shape = X_train[0].shape\n","\n","# Number of unique classes/labels in the dataset.\n","n_classes = len(np.unique(y_train))\n","\n","print(\"Number of training images: \", n_train)\n","print(\"Number of testing images: \", n_test)\n","print(\"Number of validation images: \", n_validation)\n","print(\"Image data shape =\", image_shape)\n","print(\"Number of classes =\", n_classes)"]},{"cell_type":"markdown","metadata":{"id":"aW6656bD2YT6"},"source":["# STEP 2: IMAGE EXPLORATION"]},{"cell_type":"markdown","metadata":{"id":"r3sgZFY-2YT7"},"source":["- Sample Images from the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3n-D59MF2YT7","executionInfo":{"status":"aborted","timestamp":1733191189798,"user_tz":480,"elapsed":5,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["i = 21 #Random number\n","plt.imshow(X_test[i])\n","signs[ y_test[i]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RasXFbKu2YT7","executionInfo":{"status":"aborted","timestamp":1733191189798,"user_tz":480,"elapsed":5,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["i = 34\n","plt.imshow(X_test[i])\n","signs[ y_test[i]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h8A1mfs72YT7","executionInfo":{"status":"aborted","timestamp":1733191189798,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["i = 91\n","plt.imshow(X_test[i])\n","signs[ y_test[i]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"in_eDAcf2YT7","executionInfo":{"status":"aborted","timestamp":1733191189798,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["i = 130\n","plt.imshow(X_test[i])\n","signs[ y_test[i]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PhX5jn-j2YT7","executionInfo":{"status":"aborted","timestamp":1733191189798,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["i = 136\n","plt.imshow(X_test[i])\n","signs[ y_test[i]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FWXL8LJf2YT7","executionInfo":{"status":"aborted","timestamp":1733191189798,"user_tz":480,"elapsed":87554,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["i = 165\n","plt.imshow(X_test[i])\n","signs[ y_test[i]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"urUk02sJ2YT8","executionInfo":{"status":"aborted","timestamp":1733191189799,"user_tz":480,"elapsed":87554,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["i = 154\n","plt.imshow(X_test[i])\n","signs[ y_test[i]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JbPUASVV2YT8","executionInfo":{"status":"aborted","timestamp":1733191189799,"user_tz":480,"elapsed":87552,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["i = 172\n","plt.imshow(X_test[i])\n","signs[ y_test[i]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hOMLojw12YT8","executionInfo":{"status":"aborted","timestamp":1733191189799,"user_tz":480,"elapsed":87551,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["#This function plots a histogram of the input data.\n","\n","def histogram_plot(dataset, label):\n","\n","    hist, bins = np.histogram(dataset, bins=n_classes)\n","    width = 0.7 * (bins[1] - bins[0])\n","    center = (bins[:-1] + bins[1:]) / 2\n","    plt.bar(center, hist, align='center', width=width)\n","    plt.xlabel(label)\n","    plt.ylabel(\"Image count\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cIBxb1OQ2YT8","executionInfo":{"status":"aborted","timestamp":1733191189799,"user_tz":480,"elapsed":87550,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["# Plotting histograms of the count of each sign\n","histogram_plot(y_train, \"Training images\")\n","histogram_plot(y_test, \"Testing images\")\n","histogram_plot(y_validation, \"Validation images\")"]},{"cell_type":"markdown","metadata":{"id":"aYPXeiTa2YT8"},"source":["# STEP 3: DATA PREPROCESSING"]},{"cell_type":"markdown","metadata":{"id":"I24dxlcn2YT8"},"source":["# (i) Shuffling the data"]},{"cell_type":"markdown","metadata":{"id":"q9nUt6Kv2YT8"},"source":["- In general, we shuffle the training data to increase randomness and variety in training dataset, so that after training, the model is more stable. We don't want our model to learn any kind of specific order/pattern of images."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7jIbuWcV2YT8","executionInfo":{"status":"aborted","timestamp":1733191189799,"user_tz":480,"elapsed":87550,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["from sklearn.utils import shuffle\n","X_train, y_train = shuffle(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"LOm3Y67O2YT8"},"source":["# (ii) Grayscaling"]},{"cell_type":"markdown","metadata":{"id":"8BrNmuR42YT8"},"source":["- Converting the coloured images to grayscaled images. Here, the average pixel values of three channels (RGB) is taken and a single channel is created. The dimensions of image (i.e. 32 x 32) is kept same."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7qVpPei2YT8","executionInfo":{"status":"aborted","timestamp":1733191189799,"user_tz":480,"elapsed":87549,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["X_train_gray = np.sum(X_train/3, axis=3, keepdims=True)\n","X_test_gray  = np.sum(X_test/3, axis=3, keepdims=True)\n","X_validation_gray  = np.sum(X_validation/3, axis=3, keepdims=True)"]},{"cell_type":"markdown","metadata":{"id":"rg_7io7H2YT8"},"source":["# (iii) Normalization"]},{"cell_type":"markdown","metadata":{"id":"kz41TzIZ2YT9"},"source":["- Normalization of image pixel values is done. This process makes the computation faster and the neural network learns more efficiently."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QxGrMVw82YT9","executionInfo":{"status":"aborted","timestamp":1733191190132,"user_tz":480,"elapsed":5,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["X_train_gray_norm = (X_train_gray - 128)/128\n","X_test_gray_norm = (X_test_gray - 128)/128\n","X_validation_gray_norm = (X_validation_gray - 128)/128"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LypsBjKL2YT9","executionInfo":{"status":"aborted","timestamp":1733191190132,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["X_train_gray.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W3R4CJsl2YT9","executionInfo":{"status":"aborted","timestamp":1733191190132,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["# Visualising an image before and after the data preprocessing\n","\n","i = 45  #Random number\n","plt.imshow(X_train[i])\n","print('Original Image')\n","signs[ y_train[i]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SqLKxtaI2YT9","executionInfo":{"status":"aborted","timestamp":1733191190132,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["plt.imshow(X_train_gray_norm[i].squeeze(), cmap='gray')\n","print('Grayscaled Normalized Image')\n","signs[ y_train[i]]"]},{"cell_type":"markdown","metadata":{"id":"eK4K3KvC2YT9"},"source":["# STEP 4: MODEL TRAINING"]},{"cell_type":"markdown","metadata":{"id":"PiYPW-Kn2YT9"},"source":["The LeNet Architecture Model consists of the following layers:\n","\n","- STEP 1: THE FIRST CONVOLUTIONAL LAYER #1\n","    - Input = 32x32x1\n","    - Output = 28x28x6\n","    - Used a 5x5 Filter with output depth of 6\n","    - Stride is the amount by which the filter/kernel is shifted when the filter is passed over the image\n","    - Output = (Input-Filter+1)/Stride => (32-5+1)/1 = 28\n","    - Apply a RELU (Rectified Linear Unit) Activation function to the output\n","    - Max Pooling for input, Input = 28x28x6 and Output = 14x14x6\n","\n","\n","- STEP 2: THE SECOND CONVOLUTIONAL LAYER #2\n","    - Input = 14x14x6\n","    - Output = 10x10x16\n","    - Used a 5x5 Filter with output depth of 16\n","    - Layer 2: Convolutional layer with Output = 10x10x16\n","    - Output = (Input-filter+1)/strides => 14-5+1/1 = 10\n","    - Apply a RELU Activation function to the output\n","    - Max Pooling with Input = 10x10x16 and Output = 5x5x16\n","    \n","\n","- STEP 3: FLATTENING THE NETWORK\n","    - Flatten the network with Input = 5x5x16 and Output = 400\n","    \n","\n","- STEP 4: FULLY CONNECTED LAYER 1\n","    - Layer 3: Fully Connected layer with Input = 400 and Output = 120\n","    - Apply a RELU Activation function to the output\n","    \n","\n","- STEP 5: FULLY CONNECTED LAYER 2\n","    - Layer 4: Fully Connected Layer with Input = 120 and Output = 84\n","    - Apply a RELU Activation function to the output\n","    \n","\n","- STEP 6: FULLY CONNECTED LAYER 3\n","    - Layer 5: Fully Connected layer with Input = 84 and Output = 43\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"BtQ8W96E2YUC","executionInfo":{"status":"aborted","timestamp":1733191190132,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["# Importing the required Python libraries for building Convolutional Neural Network\n","\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Flatten, Dropout\n","from keras.optimizers import Adam\n","from keras.callbacks import TensorBoard\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0FMpgyV_2YUC","executionInfo":{"status":"aborted","timestamp":1733191190132,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["image_shape = X_train_gray[i].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XoH9Ij3v2YUC","executionInfo":{"status":"aborted","timestamp":1733191190133,"user_tz":480,"elapsed":5,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["# Building the LeNet Architecture CNN model in a sequential manner/fashion.\n","cnn_model = Sequential()\n","\n","# Convolution Layer 1\n","cnn_model.add(Conv2D(filters=6, kernel_size=(5, 5), activation='relu', input_shape=(32,32,1)))\n","\n","# Pooling/Subsampling Layer 1\n","cnn_model.add(MaxPooling2D())\n","\n","# Dropout(Regularization Technique)\n","cnn_model.add(Dropout(0.4))\n","\n","\n","\n","# Convolution Layer 2\n","cnn_model.add(Conv2D(filters=16, kernel_size=(5, 5), activation='relu'))\n","\n","# Pooling/Subsampling Layer 2\n","cnn_model.add(MaxPooling2D())\n","\n","# Dropout(Regularization Technique)\n","cnn_model.add(Dropout(0.4))\n","\n","\n","\n","# Flattening the network\n","cnn_model.add(Flatten())\n","\n","# Hidden Layer 1 (Fully connected layer)\n","cnn_model.add(Dense(units=120, activation='relu'))\n","\n","# Hidden Layer 2 (Fully connected layer)\n","cnn_model.add(Dense(units=84, activation='relu'))\n","\n","# Output Layer with 43 Classes\n","cnn_model.add(Dense(units=43, activation = 'softmax'))"]},{"source":["# Compiling the model and training the model\n","\n","cnn_model.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001),metrics =['accuracy'])\n","# Changed 'lr' to 'learning_rate' within the Adam optimizer constructor."],"cell_type":"code","metadata":{"id":"ovgUWotZ3FSh","executionInfo":{"status":"aborted","timestamp":1733191190133,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"execution_count":null,"outputs":[]},{"source":["# Fitting the training dataset in the CNN model\n","\n","history = cnn_model.fit(X_train_gray_norm,\n","                        y_train,\n","                        batch_size=500,\n","                        epochs=50, # Changed 'nb_epoch' to 'epochs'\n","                        verbose=1,\n","                        validation_data = (X_validation_gray_norm,y_validation))"],"cell_type":"code","metadata":{"id":"yy_S2Wvb3N-h","executionInfo":{"status":"aborted","timestamp":1733191190133,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e5bo6Nnr2YUD"},"source":["# STEP 5: MODEL EVALUATION"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"XAjl8NNd2YUD","executionInfo":{"status":"aborted","timestamp":1733191190133,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["#Testing/Evaluating the Model with testing dataset which contains over 12000 images\n","\n","score = cnn_model.evaluate(X_test_gray_norm, y_test)\n","print('Test Accuracy : {:.2f}'.format(score[1] * 100))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LQMWydAY2YUD","executionInfo":{"status":"aborted","timestamp":1733191190133,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["#Checking the keys in history\n","history.history.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XjUg0AaW2YUD","executionInfo":{"status":"aborted","timestamp":1733191190133,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["#Plotting Training and Validation Accuracy vs Epoch number\n","\n","accuracy = history.history['accuracy']\n","val_accuracy = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(len(accuracy))\n","\n","plt.plot(epochs, accuracy, 'b', label='Training Accuracy')\n","plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dg6wKIMs2YUD","executionInfo":{"status":"aborted","timestamp":1733191190133,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["#Plotting Training and Validation Loss vs Epoch number\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Training and Validation loss')\n","plt.legend()\n","plt.show()"]},{"source":["import numpy as np\n","\n","# Getting the predictions for the test data\n","predicted_classes = np.argmax(cnn_model.predict(X_test_gray_norm), axis=-1)\n","# Use predict() and argmax() instead of predict_classes()\n","\n","# Actual classes of the test data\n","y_true_classes = y_test"],"cell_type":"code","metadata":{"id":"Ib-lvovh7qBY","executionInfo":{"status":"aborted","timestamp":1733191190133,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mbnZoQsM2YUD","executionInfo":{"status":"aborted","timestamp":1733191190133,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["# Plotting the confusion matrix\n","\n","from sklearn.metrics import confusion_matrix\n","cm = confusion_matrix(y_true_classes, predicted_classes)\n","plt.figure(figsize = (25,25))\n","sns.heatmap(cm, annot=True)"]},{"cell_type":"markdown","metadata":{"id":"eY4JfZGD2YUD"},"source":["Observation :\n","We observe some clusters in the confusion matrix above. It turns out that the various speed limits are sometimes misclassified among themselves. Similarly, traffic signs with traingular shape are misclassified among themselves. We can further improve on the model using hierarchical CNNs to first identify broader groups (like speed signs) and then have CNNs to classify finer features (such as the actual speed limit)."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"c3Kg_YW82YUD","executionInfo":{"status":"aborted","timestamp":1733191190133,"user_tz":480,"elapsed":4,"user":{"displayName":"Namrata Sudarsi","userId":"16045853599304795769"}}},"outputs":[],"source":["#Visualing the results of CNN model by comparing the Predicted class and Actual class of first 25 images from test dataset\n","\n","L = 5\n","W = 5\n","fig, axes = plt.subplots(L, W, figsize = (20,20))\n","axes = axes.ravel()\n","\n","for i in np.arange(0, L * W):\n","    axes[i].imshow(X_test[i])\n","    axes[i].set_title(\"Predicted Class ={}\\n True Class={} \".format(predicted_classes[i], y_true_classes[i] ))\n","    axes[i].axis('off')\n","\n","plt.subplots_adjust(wspace=1)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}